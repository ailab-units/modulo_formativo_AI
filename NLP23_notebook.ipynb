{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "83AuGdkQsp3Z"
      },
      "source": [
        "# **Natural Language Processing**\n",
        "\n",
        "In questo notebook faremo degli esperimenti di NLP. La prima cosa che facciamo è **importare** delle librerie che ci serviranno per gli esperimenti. La libraria dedicata all'NLP che useremo si chiama **NLTK**. Le funzioni che andremo ad utilizzare sono *wiki_bag_of_words*, che costruisce la bag of words per una pagina di Wikipedia qualsiasi, *bow_distance*, che calcola la distanza euclida tra due bag of words, *detect_language*, che assegna la lingua ad un documento, *prepare_w2v*, che crea dei word embeddings ottenuti a partire da grandi raccolte di documenti e *prepare_simpsons*, che addestra in diretta una rappresentazione word embedding basata sui dialogi delle puntate dei The Simpsons."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%capture\n",
        "from nlp_aux import wiki_bag_of_words, bow_distance, detect_language, prepare_w2v, prepare_simpsons"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **Bag of Words**\n",
        "\n",
        "Proviamo per prima cosa a costruire una **bag of words**. Scegliamo le pagine Wikipedia delle parole *Gatto*, *Matto* e *Felino*, che sono rispettivamente *Felis silvestris catus*, *Il Matto* e *Felidae*. Quello che ci aspettiamo è che parole **simili** abbiamo profili simili e parole **diverse** abbiano profili diversi."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[3mGatto\u001b[0m:\n",
            "di:     279\n",
            "e:     200\n",
            "il:     194\n",
            "la:     166\n",
            "è:     120\n",
            "gatto:     118\n",
            "in:     116\n",
            "che:     112\n",
            "i:     111\n",
            "a:     102\n"
          ]
        }
      ],
      "source": [
        "print('\\x1B[3mGatto\\x1B[0m:')\n",
        "bow_gatto = wiki_bag_of_words('Felis silvestris catus', n=10, print_bow=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[3mMatto\u001b[0m:\n",
            "il:      54\n",
            "di:      46\n",
            "e:      41\n",
            "è:      37\n",
            "un:      32\n",
            "in:      32\n",
            "la:      32\n",
            "==:      20\n",
            "che:      20\n",
            "a:      19\n"
          ]
        }
      ],
      "source": [
        "print('\\x1B[3mMatto\\x1B[0m:')\n",
        "bow_matto = wiki_bag_of_words('Il Matto', n=10, print_bow=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[3mFelino\u001b[0m:\n",
            "-:      46\n",
            "gatto:      31\n",
            "di:      28\n",
            "e:      22\n",
            "genere:      18\n",
            "i:      16\n",
            "leopardus:      15\n",
            "felidi:      14\n",
            "il:      13\n",
            "si:      13\n"
          ]
        }
      ],
      "source": [
        "print('\\x1B[3mFelino\\x1B[0m:')\n",
        "bow_felino = wiki_bag_of_words('Felidae', n=10, print_bow=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Ci accorgiamo a prima vista che qualcosa non funziona: i profili sono molto simili tra di loro e pieni di **parole funzionali**, le cosiddette stopwords. Andiamo quindi a ricalcolare i profili, questa volta **rimuovendo** le parole funzionali."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[3mGatto\u001b[0m:\n",
            "gatto:     118\n",
            "gatti:      62\n",
            "====:      34\n",
            "===:      32\n",
            "può:      31\n",
            "molto:      28\n",
            "==:      26\n",
            "pelo:      25\n",
            "durante:      19\n",
            "quando:      18\n"
          ]
        }
      ],
      "source": [
        "print('\\x1B[3mGatto\\x1B[0m:')\n",
        "bow_gatto_cleaned = wiki_bag_of_words('Felis silvestris catus', n=10, print_bow=True, remove_stop_words=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[3mMatto\u001b[0m:\n",
            "==:      20\n",
            "matto:      16\n",
            "the:      12\n",
            "può:      12\n",
            "altri:       9\n",
            "mazzi:       8\n",
            "rappresenta:       7\n",
            "tarocchi:       7\n",
            "spesso:       7\n",
            "tarocchi,:       7\n"
          ]
        }
      ],
      "source": [
        "print('\\x1B[3mMatto\\x1B[0m:')\n",
        "bow_matto_cleaned = wiki_bag_of_words('Il Matto', n=10, print_bow=True, remove_stop_words=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[3mFelino\u001b[0m:\n",
            "-:      46\n",
            "gatto:      31\n",
            "genere:      18\n",
            "leopardus:      15\n",
            "felidi:      14\n",
            "felis:      12\n",
            "==:      12\n",
            "evolutiva:      11\n",
            "panthera:       9\n",
            "famiglia:       8\n"
          ]
        }
      ],
      "source": [
        "print('\\x1B[3mFelino\\x1B[0m:')\n",
        "bow_felino_cleaned = wiki_bag_of_words('Felidae', n=10, print_bow=True, remove_stop_words=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Proviamo a misurare la **distanza euclidea** tra il profilo de *Gatto* e quelli de *Il Matto* e *Felino*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Distanza \u001b[3mGatto\u001b[0m - \u001b[3mMatto\u001b[0m: 488.39\n",
            "Distanza \u001b[3mGatto\u001b[0m - \u001b[3mFelino\u001b[0m: 537.62\n"
          ]
        }
      ],
      "source": [
        "distanza_gatto_matto = bow_distance(bow_gatto, bow_matto)\n",
        "distanza_gatto_felino = bow_distance(bow_gatto, bow_felino)\n",
        "print(f'Distanza \\x1B[3mGatto\\x1B[0m - \\x1B[3mMatto\\x1B[0m: {distanza_gatto_matto:.2f}')\n",
        "print(f'Distanza \\x1B[3mGatto\\x1B[0m - \\x1B[3mFelino\\x1B[0m: {distanza_gatto_felino:.2f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Addirittura la distanza tra *Gatto* e *Il Matto* è **minore** di quella tra *Gatto* e *Felino*, al contrario di quello che ci aspettavamo. \n",
        "\n",
        "Andiamo ora a ricalcolare le distanze tra i profili **dopo** aver rimosso le stopwords. Vediamo che adesso la distanza tra *Gatto* e *Felino* è minore di quella tra *Gatto* e *Matto*, come ci aspettavamo intuitivamente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Distanza \u001b[3mGatto\u001b[0m - \u001b[3mIl Matto\u001b[0m: 185.82\n",
            "Distanza \u001b[3mGatto\u001b[0m - \u001b[3mFelino\u001b[0m: 177.92\n"
          ]
        }
      ],
      "source": [
        "distanza_gatto_matto_cleaned = bow_distance(bow_gatto_cleaned, bow_matto_cleaned)\n",
        "distanza_gatto_felino_cleaned = bow_distance(bow_gatto_cleaned, bow_felino_cleaned)\n",
        "print(f'Distanza \\x1B[3mGatto\\x1B[0m - \\x1B[3mIl Matto\\x1B[0m: {distanza_gatto_matto_cleaned:.2f}')\n",
        "print(f'Distanza \\x1B[3mGatto\\x1B[0m - \\x1B[3mFelino\\x1B[0m: {distanza_gatto_felino_cleaned:.2f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **Language Detection**\n",
        "\n",
        "Per questo esercizio useremo l'algoritmo di **Cavnar-Trenkle**. Questo algoritmo contiene un profilo linguisto per ciascuna lingua in cui sono scritti i **molti** documenti che sono stati usati per creare questo collezione di profili linguistici. Ogni profilo è costruito usando i 300 *n-grammi* più frequenti, con *n* che va da 1 a 5.\n",
        "\n",
        "Quando si ha un documento **ignoto** di cui si vuole identificare la lingua, si costruisce il suo profilo linguistico e si misura la **distanza** tra questo e i profili delle diverse lingue, costruiti come abbiamo detto sopra. La lingua assegnata al documento ignoto, quella più probabile per questo, è quella associata al profilo di distanza minore, utilizzando la **distanza ranking**.\n",
        "\n",
        "Come esempio, usiamo questo algoritmo per trovare la lingua della frase \"La penna è sul tavolo.\", che rappresente il nostro documento, che può anche essere una singola frase come in questo caso. Vediamo che la lingua è identificata correttamente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "otQHBJTDKxs8",
        "outputId": "17df04fa-6041-4d62-f6e0-259b06531f74"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'italian'"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "detect_language(\"La penna è sul tavolo.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Come confronto, vediamo che la lingua della frase \"The pen is on the table.\" è correttamente identifica come inglese"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'english'"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "detect_language(\"The pen is on the table.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **Word Embeddings**\n",
        "\n",
        "Come ultimo esempio, andiamo ad esplorare delle rappresentazioni di parole **più complesse** delle bag of words che abbiamo visto prima. Usiamo ora **Word2vec**, che sono rappresentazioni di cui non entreremo nei dettagli, ci basta sapere che queste rappresentazioni sono ottenute addestrando una **rete neurale** a partire da una mole di documenti. In questo caso particolare, sono state utilizzate 2 collezioni di documenti: il *Movie Review Data*, una collezione di critiche cinematografiche e il *The Penn Treebank Corpus*, una collezioni di articoli del New York Times.\n",
        "\n",
        "Andiamo ad inizializzare l'oggetto *Word2vec* che andremo ad utilizzare nei nostri esperimenti. Questo ci prepara 2 embeddings, uno per ciascuno dei due documenti descritti sopra, a seconda del settore in cui vogliamo fare i nostri esperimenti."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "movie_review_data, new_york_times = prepare_w2v()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Utilizzando la rappresentazione ottenuta a partire dalle critiche cinematografiche, andiamo a vedere quali sono le parole più simili a *king*. Questo algoritmo fornisce anche una *distanza* tra la parola di input e quelle più vicine ad essa."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RoXLparbqUne",
        "outputId": "963ee2ec-6c5b-4c92-d746-817a4d81fd02"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('queen', 0.8338250517845154),\n",
              " ('edward', 0.825215756893158),\n",
              " ('chris', 0.821893572807312),\n",
              " ('stewart', 0.8206092119216919),\n",
              " ('william', 0.8151760101318359),\n",
              " ('princess', 0.8150132298469543),\n",
              " ('peter', 0.8081660270690918),\n",
              " ('captain', 0.8072478771209717),\n",
              " ('steve', 0.806297242641449),\n",
              " ('russell', 0.8055285811424255)]"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "movie_review_data.wv.most_similar(['king'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Siccome nei word embeddings le parole sono rappresentate come **vettori**, possiamo andare a fare su di essi le **operazioni matematiche** standard. Prendiamo così la parola *edward*, togliamo *man* e aggiungiamo *woman*, ottenendo dunque *edward - man + woman*. Usiamo sempre la rappresentazione ottenuta a partire dalle critiche cinematografiche. A livello di codice, raggruppiamo i termini positivi, *edward* e *woman* e quelli negativi, *man* soltanto in questo caso."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VcMBkbCM6o3S",
        "outputId": "a6b350e2-1f19-4f9b-f3f7-85d208783edc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('moore', 0.9346608519554138),\n",
              " ('lisa', 0.9283749461174011),\n",
              " ('jennifer', 0.9258882403373718),\n",
              " ('diaz', 0.9235391020774841),\n",
              " ('catherine', 0.9221835732460022),\n",
              " ('amanda', 0.9207334518432617),\n",
              " ('vincent', 0.9201065301895142),\n",
              " ('danny', 0.9194660186767578),\n",
              " ('kelly', 0.9184256196022034),\n",
              " ('patrick', 0.9172739386558533)]"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "movie_review_data.wv.most_similar(positive=['edward', 'woman'], negative=['man'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Sempre con il word embedding delle critiche cinematografiche, possiamo anche a andare a vedere quale parola **non c'entra** tra un gruppo di parole scelte. Quello che fa questa funzione è in realtà dire quale è la parola tra quelle date che c'entra **meno** con tutte le altre. Tra *king*, *queen* e *car*, la parola che non c'entra con le altre è chiaramente *car*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "id": "09Fq7XpG796W",
        "outputId": "f3854349-7b4f-432c-bc84-73161032ef66"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'car'"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "movie_review_data.wv.doesnt_match(['king', 'queen', 'car'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Sperimentiamo adesso con un word embedding ottenuto a partire dai **dialoghi** delle puntate dei **Simpsons**. A differenza dei word embeddings precedenti, questo modello ha bisogno di essere **addestrato** in diretta quindi richiede un po' più di tempo rispetto ai precedenti, che erano già addestrati."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "wWgRfs6zCncO"
      },
      "outputs": [],
      "source": [
        "the_simpsons = prepare_simpsons()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Possiamo usare questa rappresentazione per cercare la parola **più simile** ad una parola in ingresso. In questo caso cerchiamo la parola più simile a *simpson* e troviamo che questa è *homer*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mHJ4MWIUEd9_",
        "outputId": "d959a022-69e1-4d9c-a2dc-ae215d948db1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('homer', 0.6349974274635315)]"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "the_simpsons.wv.most_similar(positive=['simpson'], topn=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Proviamo ancora con una **formula**: cerchiamo in questo caso il risultato di *homer - man + woman*, raggruppando come prima i termini positivi, *homer* e *woman* e quello negativo, *man*. La parola che troviamo è *marge*, come ci aspettavamo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IZFkLA4_FY43",
        "outputId": "1799068d-4971-4eae-92e1-9c2d3ae3fe14"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('simpson', 0.34963610768318176)]"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "the_simpsons.wv.most_similar(positive=['homer', 'woman'], negative=['man'], topn=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GOuIaqy1VV_C"
      },
      "source": [
        "Proviamo come ultima cosa un esempio simile a quello appena visto, ma ora la formula è: *bart - boy + girl*. Il modello riesce a catturare le relazioni di **constesto** tra le parole. Il risultato, come ci aspettavamo, è *lisa*.\n",
        "Stessa cosa, ma con `bart` (e `boy` e `girl`)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ixSkD-q2ElLT",
        "outputId": "c3942878-e750-40e0-ea5a-fa9d10d8a31c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('lisa', 0.45863646268844604)]"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "the_simpsons.wv.most_similar(positive=['bart', 'girl'], negative=['boy'], topn=1)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "NLP.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
